{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "from tools.utils import *\n",
    "from tools.het_networks import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "seed = 42\n",
    "\n",
    "# Model\n",
    "hidden_channels = 128\n",
    "num_layers = 2\n",
    "intra_aggr='sum'\n",
    "inter_aggr='mean'\n",
    "dropout = 0.5\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "epochs = 15\n",
    "lr = 1e-4\n",
    "maxlr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seeds(seed, device)\n",
    "\n",
    "# CUDA reproducibility\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "het_dataset = torch.load('data/PSCDB/het_pscdb_graphs.pt', weights_only=False)\n",
    "len(het_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_788/740165721.py:11: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = coords.std(dim=0, unbiased=False)\n"
     ]
    }
   ],
   "source": [
    "def normalize_and_recompute_displacement(hetero_data):\n",
    "    hetero_data = hetero_data.clone()\n",
    "    for node_type in hetero_data.node_types:\n",
    "        node_data = hetero_data[node_type]\n",
    "        if hasattr(node_data, 'x') and node_data.x is not None:\n",
    "            x = node_data.x\n",
    "            if x.size(1) >= 6:\n",
    "                # Normalize free and bound coordinates\n",
    "                coords = x[:, :6]\n",
    "                mean = coords.mean(dim=0)\n",
    "                std = coords.std(dim=0, unbiased=False)\n",
    "                std[std == 0] = 1.0\n",
    "                normalized_coords = (coords - mean) / std\n",
    "                x[:, :6] = normalized_coords\n",
    "                # Recompute displacement as (bound_normalized - free_normalized)\n",
    "                free_normalized = normalized_coords[:, :3]\n",
    "                bound_normalized = normalized_coords[:, 3:6]\n",
    "                displacement_normalized = bound_normalized - free_normalized\n",
    "                x[:, 6:9] = displacement_normalized\n",
    "\n",
    "                hetero_data[node_type].x = x\n",
    "    return hetero_data\n",
    "\n",
    "# Normalize features\n",
    "normalized_het_dataset = [normalize_and_recompute_displacement(het_data) for het_data in het_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "labels = [data.y.item() for data in normalized_het_dataset]\n",
    "\n",
    "train_set, temp_set = train_test_split(\n",
    "    normalized_het_dataset, \n",
    "    test_size=0.3, \n",
    "    stratify=labels,\n",
    "    random_state=seed\n",
    "    \n",
    ")\n",
    "\n",
    "temp_labels = [data.y.item() for data in temp_set]\n",
    "valid_set, test_set = train_test_split(\n",
    "    temp_set, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_labels,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# train_loader is defined at each experiment for reproducibility\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = het_dataset[0].edge_types\n",
    "node_types = het_dataset[0].node_types\n",
    "metadata = (node_types, edge_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGNN_GraphConv(\n",
       "  (node_emb_layers): ModuleDict(\n",
       "    (A): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (C): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (D): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (E): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (F): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (G): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (H): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (I): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (K): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (L): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (M): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (N): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (P): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Q): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (R): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (S): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (T): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (V): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (W): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Y): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(-1, 128, bias=True)\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(128, 128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_blocks): ModuleList(\n",
       "    (0-1): 2 x ModuleDict(\n",
       "      (conv): HeteroConv(num_relations=420)\n",
       "      (post_lin): ModuleDict(\n",
       "        (A): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (C): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (D): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (E): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (F): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (G): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (H): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (I): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (K): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (L): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (M): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (N): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (P): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (Q): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (R): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (S): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (T): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (V): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (W): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (Y): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(-1, 128, bias=True)\n",
       "            (1): Dropout(p=0.5, inplace=False)\n",
       "            (2): Linear(128, 128, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(2560, 128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = f\"HeteroGNN_GraphConv-{hidden_channels} hidden channels-{num_layers} mlp-{num_layers} conv-{intra_aggr} intra_aggr-{inter_aggr} inter_aggr-{dropout} dropout-{lr} lr-{maxlr} maxlr-OneCylceLR-Adam-CE Loss\"\n",
    "\n",
    "reset_seeds(seed, device)\n",
    "train_loader = get_train_loader(seed, train_set, batch_size)\n",
    "model = HeteroGNN_GraphConv(metadata, hidden_channels, mlp_layers=num_layers, conv_layers=num_layers, intra_aggr=intra_aggr, inter_aggr=inter_aggr, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_loader)\n",
    "total_steps = epochs * batches_per_epoch\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=maxlr, total_steps=total_steps, epochs=epochs, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 4.4790 | Validation Loss: 2.9580\n",
      "Train Acc: 0.2371 | Validation Acc: 0.3488\n",
      "Train F1: 0.0430 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 2/15\n",
      "Train Loss: 1.9042 | Validation Loss: 1.8333\n",
      "Train Acc: 0.3422 | Validation Acc: 0.3488\n",
      "Train F1: 0.0731 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 3/15\n",
      "Train Loss: 1.8490 | Validation Loss: 1.8438\n",
      "Train Acc: 0.3239 | Validation Acc: 0.3488\n",
      "Train F1: 0.0855 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 4/15\n",
      "Train Loss: 1.8503 | Validation Loss: 1.8476\n",
      "Train Acc: 0.3472 | Validation Acc: 0.3488\n",
      "Train F1: 0.0736 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 5/15\n",
      "Train Loss: 1.8247 | Validation Loss: 1.8258\n",
      "Train Acc: 0.3472 | Validation Acc: 0.3488\n",
      "Train F1: 0.0736 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 6/15\n",
      "Train Loss: 1.8389 | Validation Loss: 1.8229\n",
      "Train Acc: 0.3472 | Validation Acc: 0.3488\n",
      "Train F1: 0.0736 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 7/15\n",
      "Train Loss: 1.8148 | Validation Loss: 1.7954\n",
      "Train Acc: 0.3472 | Validation Acc: 0.3488\n",
      "Train F1: 0.0736 | Validation F1: 0.0739\n",
      "\n",
      "Epoch 8/15\n",
      "Train Loss: 1.8041 | Validation Loss: 1.8204\n",
      "Train Acc: 0.3372 | Validation Acc: 0.3488\n",
      "Train F1: 0.0928 | Validation F1: 0.0743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'valid_loss': [],\n",
    "    'train_acc': [],\n",
    "    'valid_acc': [],\n",
    "    'train_f1': [],\n",
    "    'valid_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc, train_f1 = train(model, train_loader, optimizer, criterion, het_predict, scheduler=scheduler, device=device)\n",
    "    valid_loss, valid_acc, valid_f1 = test(model, test_loader, criterion, het_predict, device=device)\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics['train_loss'].append(train_loss)\n",
    "    metrics['valid_loss'].append(valid_loss)\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['valid_acc'].append(valid_acc)\n",
    "    metrics['train_f1'].append(train_f1)\n",
    "    metrics['valid_f1'].append(valid_f1)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Validation Acc: {valid_acc:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Validation F1: {valid_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b6712_row0_col0, #T_b6712_row0_col3, #T_b6712_row0_col5, #T_b6712_row2_col4, #T_b6712_row9_col2, #T_b6712_row14_col1, #T_b6712_row14_col4, #T_b6712_row14_col6 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row0_col1, #T_b6712_row0_col2, #T_b6712_row2_col6, #T_b6712_row7_col4, #T_b6712_row8_col4, #T_b6712_row14_col0, #T_b6712_row14_col3, #T_b6712_row14_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row0_col4, #T_b6712_row1_col4, #T_b6712_row5_col4 {\n",
       "  background-color: #105ba4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row0_col6, #T_b6712_row1_col6, #T_b6712_row5_col6 {\n",
       "  background-color: #e1edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row1_col0, #T_b6712_row7_col1 {\n",
       "  background-color: #e9f2fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row1_col1 {\n",
       "  background-color: #add0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row1_col2, #T_b6712_row10_col1, #T_b6712_row13_col2 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row1_col3 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row1_col5 {\n",
       "  background-color: #e2edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row2_col0, #T_b6712_row2_col5 {\n",
       "  background-color: #dbe9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row2_col1 {\n",
       "  background-color: #dce9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row2_col2 {\n",
       "  background-color: #e7f0fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row2_col3, #T_b6712_row5_col3 {\n",
       "  background-color: #125da6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row3_col0, #T_b6712_row5_col5 {\n",
       "  background-color: #cde0f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row3_col1 {\n",
       "  background-color: #dfebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row3_col2, #T_b6712_row9_col1 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row3_col3, #T_b6712_row4_col3 {\n",
       "  background-color: #1562a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row3_col4, #T_b6712_row11_col4 {\n",
       "  background-color: #abd0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row3_col5 {\n",
       "  background-color: #9dcae1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row3_col6 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row4_col0 {\n",
       "  background-color: #bad6eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row4_col1 {\n",
       "  background-color: #e3eef9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row4_col2, #T_b6712_row11_col2, #T_b6712_row14_col2 {\n",
       "  background-color: #f1f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row4_col4, #T_b6712_row6_col4, #T_b6712_row10_col4 {\n",
       "  background-color: #3787c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row4_col5 {\n",
       "  background-color: #bfd8ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row4_col6 {\n",
       "  background-color: #e6f0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row5_col0 {\n",
       "  background-color: #a4cce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row5_col1, #T_b6712_row9_col6 {\n",
       "  background-color: #e5eff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row5_col2, #T_b6712_row12_col6 {\n",
       "  background-color: #f5f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row6_col0 {\n",
       "  background-color: #89bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row6_col1 {\n",
       "  background-color: #eaf2fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row6_col2, #T_b6712_row13_col1 {\n",
       "  background-color: #f5fafe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row6_col3, #T_b6712_row12_col3 {\n",
       "  background-color: #084990;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row6_col5 {\n",
       "  background-color: #5ba3d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row6_col6, #T_b6712_row13_col6 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row7_col0 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row7_col2 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row7_col3 {\n",
       "  background-color: #0a539e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row7_col5 {\n",
       "  background-color: #60a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row7_col6, #T_b6712_row10_col5 {\n",
       "  background-color: #3686c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row8_col0 {\n",
       "  background-color: #539ecd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row8_col1 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row8_col2, #T_b6712_row10_col2, #T_b6712_row12_col1 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row8_col3, #T_b6712_row10_col3 {\n",
       "  background-color: #084c95;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row8_col5 {\n",
       "  background-color: #58a1cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row8_col6 {\n",
       "  background-color: #3989c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row9_col0 {\n",
       "  background-color: #3d8dc4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row9_col3 {\n",
       "  background-color: #083e81;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row9_col4, #T_b6712_row13_col4 {\n",
       "  background-color: #6caed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row9_col5 {\n",
       "  background-color: #3080bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row10_col0 {\n",
       "  background-color: #2b7bba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row10_col6 {\n",
       "  background-color: #deebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row11_col0 {\n",
       "  background-color: #1967ad;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row11_col1 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row11_col3 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row11_col5 {\n",
       "  background-color: #1d6cb1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row11_col6 {\n",
       "  background-color: #eaf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row12_col0 {\n",
       "  background-color: #0b559f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row12_col2 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row12_col4 {\n",
       "  background-color: #d6e6f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b6712_row12_col5, #T_b6712_row13_col5 {\n",
       "  background-color: #083b7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row13_col0 {\n",
       "  background-color: #084387;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b6712_row13_col3 {\n",
       "  background-color: #083471;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b6712\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b6712_level0_col0\" class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th id=\"T_b6712_level0_col1\" class=\"col_heading level0 col1\" >Train Loss</th>\n",
       "      <th id=\"T_b6712_level0_col2\" class=\"col_heading level0 col2\" >Valid Loss</th>\n",
       "      <th id=\"T_b6712_level0_col3\" class=\"col_heading level0 col3\" >Train Acc</th>\n",
       "      <th id=\"T_b6712_level0_col4\" class=\"col_heading level0 col4\" >Valid Acc</th>\n",
       "      <th id=\"T_b6712_level0_col5\" class=\"col_heading level0 col5\" >Train F1</th>\n",
       "      <th id=\"T_b6712_level0_col6\" class=\"col_heading level0 col6\" >Valid F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b6712_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_b6712_row0_col1\" class=\"data row0 col1\" >3.2948</td>\n",
       "      <td id=\"T_b6712_row0_col2\" class=\"data row0 col2\" >3.0728</td>\n",
       "      <td id=\"T_b6712_row0_col3\" class=\"data row0 col3\" >0.1987</td>\n",
       "      <td id=\"T_b6712_row0_col4\" class=\"data row0 col4\" >0.3488</td>\n",
       "      <td id=\"T_b6712_row0_col5\" class=\"data row0 col5\" >0.0626</td>\n",
       "      <td id=\"T_b6712_row0_col6\" class=\"data row0 col6\" >0.0739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b6712_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_b6712_row1_col1\" class=\"data row1 col1\" >2.1901</td>\n",
       "      <td id=\"T_b6712_row1_col2\" class=\"data row1 col2\" >1.8609</td>\n",
       "      <td id=\"T_b6712_row1_col3\" class=\"data row1 col3\" >0.3356</td>\n",
       "      <td id=\"T_b6712_row1_col4\" class=\"data row1 col4\" >0.3488</td>\n",
       "      <td id=\"T_b6712_row1_col5\" class=\"data row1 col5\" >0.0730</td>\n",
       "      <td id=\"T_b6712_row1_col6\" class=\"data row1 col6\" >0.0739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b6712_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_b6712_row2_col1\" class=\"data row2 col1\" >1.8797</td>\n",
       "      <td id=\"T_b6712_row2_col2\" class=\"data row2 col2\" >1.9210</td>\n",
       "      <td id=\"T_b6712_row2_col3\" class=\"data row2 col3\" >0.3406</td>\n",
       "      <td id=\"T_b6712_row2_col4\" class=\"data row2 col4\" >0.3101</td>\n",
       "      <td id=\"T_b6712_row2_col5\" class=\"data row2 col5\" >0.0764</td>\n",
       "      <td id=\"T_b6712_row2_col6\" class=\"data row2 col6\" >0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b6712_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_b6712_row3_col1\" class=\"data row3 col1\" >1.8533</td>\n",
       "      <td id=\"T_b6712_row3_col2\" class=\"data row3 col2\" >1.8717</td>\n",
       "      <td id=\"T_b6712_row3_col3\" class=\"data row3 col3\" >0.3372</td>\n",
       "      <td id=\"T_b6712_row3_col4\" class=\"data row3 col4\" >0.3256</td>\n",
       "      <td id=\"T_b6712_row3_col5\" class=\"data row3 col5\" >0.0987</td>\n",
       "      <td id=\"T_b6712_row3_col6\" class=\"data row3 col6\" >0.0954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b6712_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_b6712_row4_col1\" class=\"data row4 col1\" >1.8119</td>\n",
       "      <td id=\"T_b6712_row4_col2\" class=\"data row4 col2\" >1.8570</td>\n",
       "      <td id=\"T_b6712_row4_col3\" class=\"data row4 col3\" >0.3372</td>\n",
       "      <td id=\"T_b6712_row4_col4\" class=\"data row4 col4\" >0.3411</td>\n",
       "      <td id=\"T_b6712_row4_col5\" class=\"data row4 col5\" >0.0887</td>\n",
       "      <td id=\"T_b6712_row4_col6\" class=\"data row4 col6\" >0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b6712_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_b6712_row5_col1\" class=\"data row5 col1\" >1.8016</td>\n",
       "      <td id=\"T_b6712_row5_col2\" class=\"data row5 col2\" >1.8325</td>\n",
       "      <td id=\"T_b6712_row5_col3\" class=\"data row5 col3\" >0.3406</td>\n",
       "      <td id=\"T_b6712_row5_col4\" class=\"data row5 col4\" >0.3488</td>\n",
       "      <td id=\"T_b6712_row5_col5\" class=\"data row5 col5\" >0.0831</td>\n",
       "      <td id=\"T_b6712_row5_col6\" class=\"data row5 col6\" >0.0739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b6712_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_b6712_row6_col1\" class=\"data row6 col1\" >1.7642</td>\n",
       "      <td id=\"T_b6712_row6_col2\" class=\"data row6 col2\" >1.8297</td>\n",
       "      <td id=\"T_b6712_row6_col3\" class=\"data row6 col3\" >0.3539</td>\n",
       "      <td id=\"T_b6712_row6_col4\" class=\"data row6 col4\" >0.3411</td>\n",
       "      <td id=\"T_b6712_row6_col5\" class=\"data row6 col5\" >0.1154</td>\n",
       "      <td id=\"T_b6712_row6_col6\" class=\"data row6 col6\" >0.0739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b6712_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_b6712_row7_col1\" class=\"data row7 col1\" >1.7667</td>\n",
       "      <td id=\"T_b6712_row7_col2\" class=\"data row7 col2\" >1.8237</td>\n",
       "      <td id=\"T_b6712_row7_col3\" class=\"data row7 col3\" >0.3472</td>\n",
       "      <td id=\"T_b6712_row7_col4\" class=\"data row7 col4\" >0.3566</td>\n",
       "      <td id=\"T_b6712_row7_col5\" class=\"data row7 col5\" >0.1138</td>\n",
       "      <td id=\"T_b6712_row7_col6\" class=\"data row7 col6\" >0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b6712_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_b6712_row8_col1\" class=\"data row8 col1\" >1.7497</td>\n",
       "      <td id=\"T_b6712_row8_col2\" class=\"data row8 col2\" >1.8394</td>\n",
       "      <td id=\"T_b6712_row8_col3\" class=\"data row8 col3\" >0.3523</td>\n",
       "      <td id=\"T_b6712_row8_col4\" class=\"data row8 col4\" >0.3566</td>\n",
       "      <td id=\"T_b6712_row8_col5\" class=\"data row8 col5\" >0.1162</td>\n",
       "      <td id=\"T_b6712_row8_col6\" class=\"data row8 col6\" >0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b6712_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_b6712_row9_col1\" class=\"data row9 col1\" >1.7206</td>\n",
       "      <td id=\"T_b6712_row9_col2\" class=\"data row9 col2\" >1.8158</td>\n",
       "      <td id=\"T_b6712_row9_col3\" class=\"data row9 col3\" >0.3606</td>\n",
       "      <td id=\"T_b6712_row9_col4\" class=\"data row9 col4\" >0.3333</td>\n",
       "      <td id=\"T_b6712_row9_col5\" class=\"data row9 col5\" >0.1291</td>\n",
       "      <td id=\"T_b6712_row9_col6\" class=\"data row9 col6\" >0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b6712_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_b6712_row10_col1\" class=\"data row10 col1\" >1.7099</td>\n",
       "      <td id=\"T_b6712_row10_col2\" class=\"data row10 col2\" >1.8398</td>\n",
       "      <td id=\"T_b6712_row10_col3\" class=\"data row10 col3\" >0.3523</td>\n",
       "      <td id=\"T_b6712_row10_col4\" class=\"data row10 col4\" >0.3411</td>\n",
       "      <td id=\"T_b6712_row10_col5\" class=\"data row10 col5\" >0.1268</td>\n",
       "      <td id=\"T_b6712_row10_col6\" class=\"data row10 col6\" >0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b6712_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_b6712_row11_col1\" class=\"data row11 col1\" >1.6906</td>\n",
       "      <td id=\"T_b6712_row11_col2\" class=\"data row11 col2\" >1.8553</td>\n",
       "      <td id=\"T_b6712_row11_col3\" class=\"data row11 col3\" >0.3589</td>\n",
       "      <td id=\"T_b6712_row11_col4\" class=\"data row11 col4\" >0.3256</td>\n",
       "      <td id=\"T_b6712_row11_col5\" class=\"data row11 col5\" >0.1364</td>\n",
       "      <td id=\"T_b6712_row11_col6\" class=\"data row11 col6\" >0.0723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b6712_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_b6712_row12_col1\" class=\"data row12 col1\" >1.6766</td>\n",
       "      <td id=\"T_b6712_row12_col2\" class=\"data row12 col2\" >1.8695</td>\n",
       "      <td id=\"T_b6712_row12_col3\" class=\"data row12 col3\" >0.3539</td>\n",
       "      <td id=\"T_b6712_row12_col4\" class=\"data row12 col4\" >0.3178</td>\n",
       "      <td id=\"T_b6712_row12_col5\" class=\"data row12 col5\" >0.1542</td>\n",
       "      <td id=\"T_b6712_row12_col6\" class=\"data row12 col6\" >0.0706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b6712_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_b6712_row13_col1\" class=\"data row13 col1\" >1.6664</td>\n",
       "      <td id=\"T_b6712_row13_col2\" class=\"data row13 col2\" >1.8630</td>\n",
       "      <td id=\"T_b6712_row13_col3\" class=\"data row13 col3\" >0.3673</td>\n",
       "      <td id=\"T_b6712_row13_col4\" class=\"data row13 col4\" >0.3333</td>\n",
       "      <td id=\"T_b6712_row13_col5\" class=\"data row13 col5\" >0.1545</td>\n",
       "      <td id=\"T_b6712_row13_col6\" class=\"data row13 col6\" >0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b6712_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b6712_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_b6712_row14_col1\" class=\"data row14 col1\" >1.6493</td>\n",
       "      <td id=\"T_b6712_row14_col2\" class=\"data row14 col2\" >1.8562</td>\n",
       "      <td id=\"T_b6712_row14_col3\" class=\"data row14 col3\" >0.3706</td>\n",
       "      <td id=\"T_b6712_row14_col4\" class=\"data row14 col4\" >0.3101</td>\n",
       "      <td id=\"T_b6712_row14_col5\" class=\"data row14 col5\" >0.1587</td>\n",
       "      <td id=\"T_b6712_row14_col6\" class=\"data row14 col6\" >0.0701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f068f3cae30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_metrics(metrics, experiment_name)\n",
    "create_metrics_table(metrics, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"HeteroGNN_SAGEConv-{hidden_channels} hidden channels-{num_layers} mlp-{num_layers} conv-{intra_aggr} intra_aggr-{inter_aggr} inter_aggr-{dropout} dropout-{lr} lr-{maxlr} maxlr-OneCylceLR-Adam-CE Loss\"\n",
    "\n",
    "reset_seeds(seed, device)\n",
    "train_loader = get_train_loader(seed, train_set, batch_size)\n",
    "model = HeteroGNN_SAGEConv(metadata, hidden_channels, mlp_layers=num_layers, conv_layers=num_layers, intra_aggr=intra_aggr, inter_aggr=inter_aggr, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_loader)\n",
    "total_steps = epochs * batches_per_epoch\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=maxlr, total_steps=total_steps, epochs=epochs, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'valid_loss': [],\n",
    "    'train_acc': [],\n",
    "    'valid_acc': [],\n",
    "    'train_f1': [],\n",
    "    'valid_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc, train_f1 = train(model, train_loader, optimizer, criterion, het_predict, scheduler=scheduler, device=device)\n",
    "    valid_loss, valid_acc, valid_f1 = test(model, test_loader, criterion, het_predict, device=device)\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics['train_loss'].append(train_loss)\n",
    "    metrics['valid_loss'].append(valid_loss)\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['valid_acc'].append(valid_acc)\n",
    "    metrics['train_f1'].append(train_f1)\n",
    "    metrics['valid_f1'].append(valid_f1)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Validation Acc: {valid_acc:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Validation F1: {valid_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, experiment_name)\n",
    "create_metrics_table(metrics, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"HeteroGNN_GATConv-{hidden_channels} hidden channels-{num_layers} mlp-{num_layers} conv-{intra_aggr} intra_aggr-{inter_aggr} inter_aggr-{dropout} dropout-{lr} lr-{maxlr} maxlr-OneCylceLR-Adam-CE Loss\"\n",
    "\n",
    "reset_seeds(seed, device)\n",
    "train_loader = get_train_loader(seed, train_set, batch_size)\n",
    "model = HeteroGNN_GATConv(metadata, hidden_channels, mlp_layers=num_layers, conv_layers=num_layers, intra_aggr=intra_aggr, inter_aggr=inter_aggr, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_loader)\n",
    "total_steps = epochs * batches_per_epoch\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=maxlr, total_steps=total_steps, epochs=epochs, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'valid_loss': [],\n",
    "    'train_acc': [],\n",
    "    'valid_acc': [],\n",
    "    'train_f1': [],\n",
    "    'valid_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc, train_f1 = train(model, train_loader, optimizer, criterion, het_predict, scheduler=scheduler, device=device)\n",
    "    valid_loss, valid_acc, valid_f1 = test(model, test_loader, criterion, het_predict, device=device)\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics['train_loss'].append(train_loss)\n",
    "    metrics['valid_loss'].append(valid_loss)\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['valid_acc'].append(valid_acc)\n",
    "    metrics['train_f1'].append(train_f1)\n",
    "    metrics['valid_f1'].append(valid_f1)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Validation Acc: {valid_acc:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Validation F1: {valid_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, experiment_name)\n",
    "create_metrics_table(metrics, experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
